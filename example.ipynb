{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chunwei/anaconda3/envs/flight/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-01-05 21:42:38.254138: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-05 21:42:38.419377: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-05 21:42:39.063704: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/chunwei/anaconda3/envs/flight/lib/python3.8/site-packages/cv2/../../lib64:/opt/ros/noetic/lib:/home/chunwei/rslgym_build/lib:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.3/lib64:/home/chunwei/rslgym_build/lib:/home/chunwei/rslgym_build/lib:/home/chunwei/rslgym_build/lib:/home/chunwei/rslgym_build/lib:/home/chunwei/Documents/2021FALL/FoRL/Project/acados/lib:/home/chunwei/rslgym_build/lib:/home/chunwei/rslgym_build/lib:/home/chunwei/Documents/2021FALL/FoRL/Project/acados/lib:/home/chunwei/rslgym_build/lib:/home/chunwei/rslgym_build/lib:/home/chunwei/Documents/2021FALL/FoRL/Project/acados/lib\n",
      "2023-01-05 21:42:39.063820: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/chunwei/anaconda3/envs/flight/lib/python3.8/site-packages/cv2/../../lib64:/opt/ros/noetic/lib:/home/chunwei/rslgym_build/lib:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.3/lib64:/home/chunwei/rslgym_build/lib:/home/chunwei/rslgym_build/lib:/home/chunwei/rslgym_build/lib:/home/chunwei/rslgym_build/lib:/home/chunwei/Documents/2021FALL/FoRL/Project/acados/lib:/home/chunwei/rslgym_build/lib:/home/chunwei/rslgym_build/lib:/home/chunwei/Documents/2021FALL/FoRL/Project/acados/lib:/home/chunwei/rslgym_build/lib:/home/chunwei/rslgym_build/lib:/home/chunwei/Documents/2021FALL/FoRL/Project/acados/lib\n",
      "2023-01-05 21:42:39.063828: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from samples.CLS2IDX import CLS2IDX\n",
    "import os\n",
    "from pathlib import Path\n",
    "from trans_exp.utils.load_weights import load_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trans_exp.baselines.ViT.ViT_LRP import vit_base_patch16_224 as vit_LRP\n",
    "from trans_exp.baselines.ViT.ViT_explanation_generator import LRP\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "# create heatmap from mask on image\n",
    "def show_cam_on_image(img, mask):\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "    cam = heatmap + np.float32(img)\n",
    "    cam = cam / np.max(cam)\n",
    "    return cam\n",
    "\n",
    "# initialize ViT pretrained\n",
    "model = vit_LRP(pretrained=True).cuda()\n",
    "model.eval()\n",
    "attribution_generator = LRP(model)\n",
    "\n",
    "def generate_visualization(original_image, class_index=None):\n",
    "    transformer_attribution = attribution_generator.generate_LRP(original_image.unsqueeze(0).cuda(), method=\"transformer_attribution\", index=class_index).detach()\n",
    "    transformer_attribution = transformer_attribution.reshape(1, 1, 14, 14)\n",
    "    transformer_attribution = torch.nn.functional.interpolate(transformer_attribution, scale_factor=16, mode='bilinear')\n",
    "    transformer_attribution = transformer_attribution.reshape(224, 224).cuda().data.cpu().numpy()\n",
    "    transformer_attribution = (transformer_attribution - transformer_attribution.min()) / (transformer_attribution.max() - transformer_attribution.min())\n",
    "    image_transformer_attribution = original_image.permute(1, 2, 0).data.cpu().numpy()\n",
    "    image_transformer_attribution = (image_transformer_attribution - image_transformer_attribution.min()) / (image_transformer_attribution.max() - image_transformer_attribution.min())\n",
    "    vis = show_cam_on_image(image_transformer_attribution, transformer_attribution)\n",
    "    vis =  np.uint8(255 * vis)\n",
    "    vis = cv2.cvtColor(np.array(vis), cv2.COLOR_RGB2BGR)\n",
    "    return vis\n",
    "\n",
    "def print_top_classes(predictions, **kwargs):    \n",
    "    # Print Top-5 predictions\n",
    "    prob = torch.softmax(predictions, dim=1)\n",
    "    class_indices = predictions.data.topk(5, dim=1)[1][0].tolist()\n",
    "    max_str_len = 0\n",
    "    class_names = []\n",
    "    for cls_idx in class_indices:\n",
    "        class_names.append(CLS2IDX[cls_idx])\n",
    "        if len(CLS2IDX[cls_idx]) > max_str_len:\n",
    "            max_str_len = len(CLS2IDX[cls_idx])\n",
    "    \n",
    "    print('Top 5 classes:')\n",
    "    for cls_idx in class_indices:\n",
    "        output_string = '\\t{} : {}'.format(cls_idx, CLS2IDX[cls_idx])\n",
    "        output_string += ' ' * (max_str_len - len(CLS2IDX[cls_idx])) + '\\t\\t'\n",
    "        output_string += 'value = {:.3f}\\t prob = {:.1f}%'.format(predictions[0, cls_idx], 100 * prob[0, cls_idx])\n",
    "        print(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flightmare_path = Path(os.environ[\"FLIGHTMARE_PATH\"])\n",
    "sample_path = flightmare_path / \"flightpy/results/students/teacher_PPO_5/12-26-14-24-47/data/000/000437.npz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cat-Dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('samples/catdog.png')\n",
    "dog_cat_image = transform(image)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3)\n",
    "axs[0].imshow(image);\n",
    "axs[0].axis('off');\n",
    "\n",
    "output = model(dog_cat_image.unsqueeze(0).cuda())\n",
    "print_top_classes(output)\n",
    "\n",
    "# cat - the predicted class\n",
    "cat = generate_visualization(dog_cat_image)\n",
    "\n",
    "# dog \n",
    "# generate visualization for class 243: 'bull mastiff'\n",
    "dog = generate_visualization(dog_cat_image, class_index=243)\n",
    "\n",
    "\n",
    "axs[1].imshow(cat);\n",
    "axs[1].axis('off');\n",
    "axs[2].imshow(dog);\n",
    "axs[2].axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tusker-Zebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('samples/el2.png')\n",
    "tusker_zebra_image = transform(image)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3)\n",
    "axs[0].imshow(image);\n",
    "axs[0].axis('off');\n",
    "\n",
    "output = model(tusker_zebra_image.unsqueeze(0).cuda())\n",
    "print_top_classes(output)\n",
    "\n",
    "# tusker - the predicted class\n",
    "tusker = generate_visualization(tusker_zebra_image)\n",
    "\n",
    "# zebra \n",
    "# generate visualization for class 340: 'zebra'\n",
    "zebra = generate_visualization(tusker_zebra_image, class_index=340)\n",
    "\n",
    "\n",
    "axs[1].imshow(tusker);\n",
    "axs[1].axis('off');\n",
    "axs[2].imshow(zebra);\n",
    "axs[2].axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('samples/dogbird.png')\n",
    "dog_bird_image = transform(image)\n",
    "\n",
    "print(dog_bird_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3)\n",
    "axs[0].imshow(image);\n",
    "axs[0].axis('off');\n",
    "\n",
    "output = model(dog_bird_image.unsqueeze(0).cuda())\n",
    "print_top_classes(output)\n",
    "\n",
    "# basset - the predicted class\n",
    "basset = generate_visualization(dog_bird_image, class_index=161)\n",
    "\n",
    "# generate visualization for class 87: 'African grey, African gray, Psittacus erithacus (grey parrot)'\n",
    "parrot = generate_visualization(dog_bird_image, class_index=87)\n",
    "\n",
    "\n",
    "axs[1].imshow(basset);\n",
    "axs[1].axis('off');\n",
    "axs[2].imshow(parrot);\n",
    "axs[2].axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = np.load(sample_path)\n",
    "\n",
    "image = Image.fromarray(image[\"rgb\"].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(image);\n",
    "axs[0].axis('off');\n",
    "\n",
    "image = transform(image)\n",
    "\n",
    "print(image.shape)\n",
    "\n",
    "output = model(image.unsqueeze(0).cuda())\n",
    "print_top_classes(output)\n",
    "\n",
    "# tusker - the predicted class\n",
    "tusker = generate_visualization(image)\n",
    "\n",
    "# zebra \n",
    "# generate visualization for class 340: 'zebra'\n",
    "# zebra = generate_visualization(image, class_index=340)\n",
    "\n",
    "\n",
    "axs[1].imshow(tusker);\n",
    "axs[1].axis('off');\n",
    "# axs[2].imshow(zebra);\n",
    "# axs[2].axis('off');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "7605093629cb18fcce5e9851ee580088d6671b36cffe2f96996ec104406ff14d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
